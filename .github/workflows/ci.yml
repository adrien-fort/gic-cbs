name: CI

on:
  push:
    branches:
      - main
  pull_request:
    branches:
      - main
  workflow_dispatch:

jobs:
  test:
    name: Run Pytest
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
      - name: Run tests with coverage
        run: pytest --cov=src --cov-report=xml
      - name: Upload coverage report
        uses: actions/upload-artifact@v4
        with:
          name: coverage-report
          path: coverage.xml

  sonarqube:
    name: SonarQube Static Analysis
    runs-on: ubuntu-latest
    needs: test
    steps:
      - uses: actions/checkout@v3
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
      - name: Download coverage report
        uses: actions/download-artifact@v4
        with:
          name: coverage-report
          path: .
      - name: SonarQube Scan
        uses: sonarsource/sonarqube-scan-action@v2.0.0
        env:
          SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}
          SONAR_HOST_URL: https://sonarcloud.io
        with:
          args: >
            -Dsonar.projectKey=adrien-fort_gic-cbs
            -Dsonar.organization=adrien-fort
            -Dsonar.python.coverage.reportPaths=coverage.xml
      - name: SonarQube Quality Gate
        uses: sonarsource/sonarqube-quality-gate-action@v1.1.0
        env:
          SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}
          SONAR_HOST_URL: https://sonarcloud.io
        with:
          scanMetadataReportFile: .scannerwork/report-task.txt

  docs:
    name: Build Sphinx Documentation
    runs-on: ubuntu-latest
    needs: sonarqube
    steps:
      - uses: actions/checkout@v3
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install 'sphinx>=5.0'
      - name: Build Sphinx docs
        run: |
          cd docs
          sphinx-build -b html . _build/html
      - name: Upload Sphinx HTML docs
        uses: actions/upload-artifact@v4
        with:
          name: sphinx-html-docs-${{ github.run_number }}
          path: docs/_build/html

  build-docker:
    name: Build and Save Docker Image
    runs-on: ubuntu-latest
    needs: docs
    steps:
      - uses: actions/checkout@v4
      - name: Build Docker image
        run: |
          docker build -t gic-cbs:${{ github.run_number }} -t gic-cbs:latest .
      - name: Save Docker image as artifact
        run: |
          docker save gic-cbs:${{ github.run_number }} | gzip > gic-cbs-${{ github.run_number }}.tar.gz
      - name: Upload Docker image artifact
        uses: actions/upload-artifact@v4
        with:
          name: docker-image
          path: gic-cbs-${{ github.run_number }}.tar.gz

  terraform-apply:
    name: Terraform Apply
    runs-on: ubuntu-latest
    needs: build-docker
    steps:
      - uses: actions/checkout@v4
      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
      - name: Azure Login
        uses: azure/login@v2
        with:
          creds: ${{ secrets.AZURE_CREDENTIALS }}
      - name: Terraform Import & Apply (robust)
        env:
          ARM_SUBSCRIPTION_ID: ${{ secrets.AZURE_SUBSCRIPTION_ID }}
        run: |
          cd infra
          terraform init

          # Import existing resource group if needed
          if az group show --name gic-cbs-rg --query id -o tsv >/dev/null 2>&1; then
            echo "Resource group exists in Azure, checking Terraform state..."
            if ! terraform state list | grep -q azurerm_resource_group.gic_cbs; then
              echo "Importing existing resource group into Terraform state..."
              terraform import azurerm_resource_group.gic_cbs /subscriptions/${{ secrets.AZURE_SUBSCRIPTION_ID }}/resourceGroups/gic-cbs-rg || echo "Import may have failed, continuing..."
            else
              echo "Resource group already managed by Terraform"
            fi
          else
            echo "Resource group does not exist in Azure, Terraform will create it"
          fi

          # Import existing AKS cluster if needed
          if az aks show --resource-group gic-cbs-rg --name gic-cbs-aks --query id -o tsv >/dev/null 2>&1; then
            echo "AKS cluster exists in Azure, checking Terraform state..."
            if ! terraform state list | grep -q azurerm_kubernetes_cluster.gic_cbs_aks; then
              echo "Importing existing AKS cluster into Terraform state..."
              terraform import azurerm_kubernetes_cluster.gic_cbs_aks /subscriptions/${{ secrets.AZURE_SUBSCRIPTION_ID }}/resourceGroups/gic-cbs-rg/providers/Microsoft.ContainerService/managedClusters/gic-cbs-aks || echo "Import may have failed, continuing..."
            else
              echo "AKS cluster already managed by Terraform"
            fi
          else
            echo "AKS cluster does not exist in Azure, Terraform will create it"
          fi

          # Import existing ACR if needed
          if az acr show --name giccbsacrforta20250924 --resource-group gic-cbs-rg --query id -o tsv >/dev/null 2>&1; then
            echo "ACR exists in Azure, checking Terraform state..."
            if ! terraform state list | grep -q azurerm_container_registry.gic_cbs_acr; then
              echo "Importing existing ACR into Terraform state..."
              terraform import azurerm_container_registry.gic_cbs_acr /subscriptions/${{ secrets.AZURE_SUBSCRIPTION_ID }}/resourceGroups/gic-cbs-rg/providers/Microsoft.ContainerRegistry/registries/giccbsacrforta20250924 || echo "Import may have failed, continuing..."
            else
              echo "ACR already managed by Terraform"
            fi
          else
            echo "ACR does not exist in Azure, Terraform will create it"
          fi

          terraform plan -no-color
          terraform apply -auto-approve

  deploy-aks:
    name: Deploy to AKS
    runs-on: ubuntu-latest
    needs: terraform-apply
    steps:
      - uses: actions/checkout@v4
      - name: Azure Login
        uses: azure/login@v2
        with:
          creds: ${{ secrets.AZURE_CREDENTIALS }}
      - name: Download Docker image artifact
        uses: actions/download-artifact@v4
        with:
          name: docker-image
      - name: Load Docker image
        run: |
          gunzip -c gic-cbs-${{ github.run_number }}.tar.gz | docker load
      - name: Push to Azure Container Registry
        run: |
          ACR_NAME=giccbsacrforta20250924
          az acr login --name $ACR_NAME
          ACR_LOGIN_SERVER=$(az acr show --name $ACR_NAME --query "loginServer" -o tsv)
          docker tag gic-cbs:${{ github.run_number }} $ACR_LOGIN_SERVER/gic-cbs:${{ github.run_number }}
          docker push $ACR_LOGIN_SERVER/gic-cbs:${{ github.run_number }}
      - name: Get AKS credentials
        run: |
          az aks get-credentials --resource-group gic-cbs-rg --name gic-cbs-aks --overwrite-existing
      - name: Update image in manifest
        run: |
          ACR_NAME=giccbsacrforta20250924
          ACR_LOGIN_SERVER=$(az acr show --name $ACR_NAME --query "loginServer" -o tsv)
          sed -i "s|<your-acr-name>.azurecr.io|$ACR_LOGIN_SERVER|g" infra/k8s-deployment.yaml
          sed -i "s|:latest|:${{ github.run_number }}|g" infra/k8s-deployment.yaml
      - name: Apply Kubernetes manifests
        run: kubectl apply -f infra/k8s-deployment.yaml
      - name: Wait for rollout
        run: kubectl rollout status deployment/gic-cbs
        continue-on-error: true

      - name: Get pod and node status
        run: |
          kubectl get pods -o wide
          kubectl describe nodes

      - name: Describe failing pod (if any)
        run: |
          FAILING_PODS=$(kubectl get pods --field-selector=status.phase!=Running -o jsonpath='{.items[*].metadata.name}')
          if [ -z "$FAILING_PODS" ]; then
            echo "All pods are running."
            exit 0
          fi
          for POD in $FAILING_PODS; do
            kubectl describe pod $POD
            kubectl logs $POD || true
          done

  owasp-zap:
    name: OWASP ZAP Scan
    runs-on: ubuntu-latest
    needs: deploy-aks
    env:
      AKS_SERVICE_NAME: gic-cbs
      AKS_NAMESPACE: default
    steps:
      - name: Azure Login
        uses: azure/login@v2
        with:
          creds: ${{ secrets.AZURE_CREDENTIALS }}
      - name: Get AKS credentials
        run: az aks get-credentials --resource-group gic-cbs-rg --name gic-cbs-aks --overwrite-existing
      - name: Get AKS app public IP
        id: get_ip
        run: |
          APP_IP=$(kubectl get svc $AKS_SERVICE_NAME --namespace $AKS_NAMESPACE -o jsonpath='{.status.loadBalancer.ingress[0].ip}')
          echo "APP_URL=http://$APP_IP" >> $GITHUB_ENV
      - name: Run OWASP ZAP
        run: |
          docker run -t owasp/zap2docker-stable zap-baseline.py -t ${{ env.APP_URL }}

  rollback-aks:
    name: Rollback AKS Deployment
    runs-on: ubuntu-latest
    needs: []
    permissions:
      id-token: write
      contents: read
    steps:
      - uses: actions/checkout@v4
      - name: Azure Login
        uses: azure/login@v2
        with:
          creds: ${{ secrets.AZURE_CREDENTIALS }}
      - name: Get AKS credentials
        run: |
          az aks get-credentials --resource-group gic-cbs-rg --name gic-cbs-aks --overwrite-existing
      - name: Rollback deployment
        run: |
          kubectl rollout undo deployment/gic-cbs
      - name: Show rollout history
        run: |
          kubectl rollout history deployment/gic-cbs